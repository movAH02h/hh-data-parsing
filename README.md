# HH Data Parsing & Preprocessing

Первый этап конвейера обработки данных резюме с портала HeadHunter. Модуль преобразует сырые выгрузки в структурированные данные, готовые для машинного обучения.

## Основной функционал
- **Загрузка и исправление кодировки**: Чтение файлов в `cp1251` и автоматическое устранение Mojibake (ошибок двойного кодирования).
- **Пайплайн на основе Chain of Responsibility**: Модульная архитектура позволяет легко добавлять или менять этапы обработки.
- **Экстракция признаков**: Автоматическое извлечение числового значения заработной платы и кодирование категориальных переменных.
- **Генерация данных для ML**: Создание финальных массивов признаков ($X$) и целевой переменной ($y$) в формате NumPy.

## Структура выходных данных
После запуска в директории `data/` появятся:
1. `hh_cleaned.csv` — очищенный текст в кодировке UTF-8.
2. `x_data.npy` — матрица признаков (факторизованные категории).
3. `y_data.npy` — вектор целевой переменной (зарплата).

## Инструкция по запуску
1. Склонируйте репозиторий и создайте папку `data/`, поместите туда исходный файл `hh.csv`.
2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
